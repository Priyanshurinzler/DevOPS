WHAT is DOCKER

	Open source platform for automating the deployment of apps as lightweight, portable containers
	CONTAINERS are  isolated processes that share the OS kernel but have their own filesystems, networking, and process space.

KEY Components
	
	Docker Engine		Core client-server architecture (daemon dockerd + CLI docker)
	Docker Images		Immutable application templates (built from Dockerfiles)
	Docker Containers	Running instances of images
	Dockerfile		Script to define how to build an image
	Docker Hub		Public image registry
	Docker Compose		Tool to define and run multi-container applications (docker-compose.yml)
	
CORE 

	1: Images
		Built from layers ( Reusable file system deltas )
		Created via Dockerfile
		docker build -t myapp
		
	2: Container
		Running instance of an image.
		Runs in an isolated runtime environment.
		start a container >>> docker run -d -p 80:80 nginx
	
	3: Dockerfile
		Defines how to build an image
		Key Instructions :
			FROM 			: specifie base image
			COPY, ADD		: Copy files
			RUN 			: Commands to run at build time
			CMD, ENTRYPOINT         : Default commands
			EXPOSE 			: Expose the port 
	
	4: Volumes
		Persistant storage shared between host and container
		docker volume create mydata
		
	5: Network
		Docker has in-built network driver system 
			Bridge ( default for single host )
			host ( shares host's network )
			overlay ( multihost )
		Container communication uses these networks
	
	6: Docker Compose
		YAML file for multi container setups
		example >>>>
				version: "3"
				services:
					web:
						image: nginx
						ports:
						- "8080:80"
					db:
						image: mysql
						environment:
						MYSQL_ROOT_PASSWORD: root
	
	7: Docker Registry
		Docker Hub is the default.
		Private registries (Harbor, AWS ECR, GCP Artifact Registry) can be used.
	
COMMON Commands
	docker ps				List running containers
	docker images			        List local images
	docker logs <container>			View logs
	docker exec -it <container> bash	Run command in running container
	docker stop/start <container>		Manage container lifecycle
	docker rm <container>			Remove container
	docker rmi <image>			Remove image
	
Common Issues and debugging
	1: Containers Exiting Immediately
		docker ps -a
		# Container status: Exited (0) seconds ago
		
		Cause:
		The container‚Äôs main process (PID 1) finished quickly.

		Solution:
		Check the container‚Äôs logs: docker logs <container>
	
	2: Port Conflicts
		Cause:		Host port already in use.

		Solution:	Change the port mapping in docker run or docker-compose.yml: 	docker run -d -p 8081:80 nginx
		OR 
		stop the process using conflicting port : sudo lsof -i :8080, sudo kill <pid>
	
	3: Cannot connect to docker Daemon
		Cause:		Docker service not running or permissions issue.
		
		Solution:   Start docker 			 >>> sudo systemctl start docker
			    Add user to docker group 		 >>> sudo usermod -aG docker $USER; newgrp docker



Common questions
‚úÖ What is Docker? Why use it?
	Docker is a platform that allows you to package an application and its dependencies into a container so it can run reliably across any environment.

	Why use Docker?

		Portability: "It works on my machine" problem solved.
		
		Lightweight: Uses host OS kernel, less overhead than VMs.
		
		Consistent deployments across dev, test, and prod.
		
		Isolation: Each container runs independently.
		
		Fast startup and shutdown times.
		
		
		
‚úÖ How is Docker different from virtual machines?


| Feature        | Docker (Container)    | Virtual Machine |
| -------------- | --------------------- | --------------- |
| Architecture   | Shares host OS kernel | Full guest OS   |
| Resource Usage | Lightweight           | Heavyweight     |
| Startup Time   | Seconds               | Minutes         |
| Isolation      | Process-level         | Hardware-level  |
| Portability    | Highly portable       | Less portable   |




‚úÖ What is a Docker image?
	A Docker image is a read-only template that contains:

		The application code
		
		All its dependencies
		
		OS libraries, runtimes, and configuration
		
		Containers are created from images.
		
		Think of an image like a blueprint; containers are the running instances of that blueprint.
		


‚úÖ What happens when you run docker run?
	
	When you execute docker run:
	
		Docker checks if the image exists locally.
		
		If not, it pulls it from the Docker registry.
		
		It creates a container based on the image.
		
		Allocates resources (CPU, memory, networking, volumes).
		
		Starts the main process (specified in CMD or ENTRYPOINT).
		
		The container continues to run as long as the process runs.
		
		
‚úÖ Explain Dockerfile structure.

A Dockerfile is a script with instructions to build an image.


FROM 				‚Äî base image
RUN 				‚Äî execute commands to install dependencies
COPY / ADD			‚Äî copy files into image
WORKDIR 			‚Äî set working directory inside container
EXPOSE 				‚Äî declare which ports are exposed
CMD or ENTRYPOINT 	‚Äî default command when container starts


‚úÖ How do you persist data in Docker?
	By default, Docker containers are ephemeral ‚Äî when a container is deleted, its data is lost.
	
	To persist data:
	
		Use Docker volumes
		
		Use bind mounts
		
		Use external storage or databases
		

‚úÖ What is a Docker volume?
	A Docker volume is:

		A managed storage mechanism provided by Docker.
		
		Stored under /var/lib/docker/volumes/ on the host.
		
		Decouples data from containers (data stays even if container is deleted).
		
	‚úÖ Why use volumes:
		
		Easier data backup/restore
		
		Managed by Docker (less prone to permission issues)
		
		Recommended for production use
		
	docker volume create mydata
	docker volume ls
	docker volume inspect mydata




‚úÖ How does Docker networking work?
Docker provides several built-in network drivers:

| Network Type         | Use Case                                                               |
| -------------------- | ---------------------------------------------------------------------- |
| **bridge** (default) | Isolated networks for containers on the same host                      |
| **host**             | Shares host network stack (no isolation)                               |
| **none**             | No networking                                                          |
| **overlay**          | Used in Swarm for multi-host networking                                |
| **macvlan**          | Assigns MAC addresses to containers (acts like real network interface) |


‚úÖ Explain multi-stage builds in Dockerfile.
	
	Multi-stage builds help create smaller, optimized images.

	‚úÖ You use multiple FROM statements:
	
		First stage: build app
		
		Final stage: copy only what is needed for runtime
		
		
		SAMPLE illustration :
		
		# Stage 1: Build
		FROM golang:1.20 AS builder
		WORKDIR /app
		COPY . .
		RUN go build -o myapp
		
		# Stage 2: Runtime
		FROM alpine:latest
		WORKDIR /app
		COPY --from=builder /app/myapp .
		CMD ["./myapp"]
		
		
	‚úÖ Benefit:

		Final image only contains runtime binaries.
		
		Build dependencies aren‚Äôt shipped ‚Üí smaller, safer images.
		


‚úÖ What is Docker Compose? How is it useful?
	Docker Compose is a tool to define and run multi-container Docker applications.

	‚úÖ Use a docker-compose.yml file to:

		Define services
		
		Set up networking
		
		Configure volumes
		
		Set environment variables
	
	‚úÖ Why useful:

		Easy local development
		
		Start multiple services with one command:
		
		
‚úÖ What is the difference between ENTRYPOINT and CMD?

|                  | ENTRYPOINT                                 | CMD                                |
| ---------------- | ------------------------------------------ | ---------------------------------- |
| **Purpose**      | Defines the main container process         | Provides default arguments         |
| **Overridable?** | No (unless overridden with `--entrypoint`) | Yes (can override at `docker run`) |
| **Usage**        | Use for fixed commands                     | Use for default args               |


	‚úÖ Quick rule of thumb:
	
		Use ENTRYPOINT when you always want a fixed command.
		
		Use CMD to supply default values that can be overridden.
		

‚úÖ How do you optimize Docker images?
üîß Techniques to optimize:

	Use smaller base images (e.g., alpine, slim variants).
	
	Use multi-stage builds to separate build dependencies from runtime.
	
	Combine related RUN commands to reduce layers:
	
	Remove unnecessary files (logs, caches, temp files).

	Use .dockerignore to exclude files/folders not needed in the image.
	
	Pin versions for better caching.
	
	
	
‚úÖ Explain the role of Docker Registry (Docker Hub vs private registry).
	üîß Docker Registry:
	
		A storage and distribution system for Docker images.
	
	‚úÖ Docker Hub (public registry):
	
		Default registry (docker pull nginx actually pulls from Docker Hub).
	
		Free tier with public repositories, paid plans for private repos.
	
	‚úÖ Private Registries (self-hosted or cloud providers):
	
		Used for enterprise security, control, compliance.
	
		Examples:
		
		AWS ECR (Elastic Container Registry)
		
		Azure Container Registry (ACR)
		
		Google Artifact Registry
		
		Harbor (open-source)
		
		
		
‚úÖ How do you secure Docker containers?
	üîê Best practices:
	
	Use official, verified base images.
	
	Run containers as non-root users.
	
	Limit container privileges (--cap-drop, --security-opt).
	
	Use read-only file systems (--read-only).
	
	Limit exposed ports.
	
	Use secrets management (not hardcoded passwords).
	
	Keep Docker engine updated.
	
	Regularly scan images for vulnerabilities.
	
	
‚úÖ How do you handle container resource limits (CPU/Memory)?

	By default, Docker containers can consume unlimited resources of the host. You control limits with flags:
	
		‚úÖ Memory:
		docker run -m 512m my-image
	
		‚úÖ CPU:
		docker run --cpus="1.5" my-image
	
		‚úÖ Docker Compose:
		deploy:
			resources:
				limits:
					cpus: '1.0'
					memory: 512M
	
	‚úÖ Benefits:

		Prevents one container from starving others.
		
		Helps with resource planning in production.
		
		

‚úÖ How do you debug a failed Docker build?
üîç Steps:

	Add --progress=plain to see more verbose logs.

		docker build --progress=plain .
	
	Use docker history <image> to inspect layers.
	
	Use intermediate RUN steps with echo or ls to verify files exist.
	
	Test build commands manually in a base image container.
	
	Check Dockerfile syntax (missing context, invalid paths).
	
	Use smaller build context (.) to avoid unnecessary file uploads.
	
	
‚úÖ Explain difference between bridge, host, and overlay networks.

| Network Type | Description                                         | Use Case                             |
| ------------ | --------------------------------------------------- | ------------------------------------ |
| **bridge**   | Default network; containers on same host can talk   | Most local development               |
| **host**     | Container shares host network stack (no isolation)  | High-performance use-cases           |
| **overlay**  | Allows containers on different hosts to communicate | Docker Swarm / multi-host networking |




‚úÖ How do you scan Docker images for vulnerabilities?
	üîê Tools for image scanning:
	
		Docker Scan (powered by Snyk):	docker scan my-image
		
		Trivy (lightweight, fast open-source scanner):	trivy image my-image
		
		Clair, Anchore, Aqua Security (enterprise tools)
	
		Integrated cloud registries (ECR, ACR, GCR all support scanning).
	
	‚úÖ Best practice:
	
	Integrate scanning into CI/CD pipeline.
	
	Fail builds on critical vulnerabilities.
	
	
	
‚úÖ Describe how you containerized a legacy application.
	üîß General steps:
	
	1Ô∏è. Understand the app dependencies:
	
		OS packages, language runtimes, database connections, storage, config files.
	
	2Ô∏è. Create Dockerfile:
	
		Pick a base image (e.g., ubuntu, alpine, node, tomcat etc.)
		
		Install dependencies using RUN.
		
		Copy app code using COPY.
		
		Expose required ports via EXPOSE.
		
		Set entrypoint or startup commands.
	
	3Ô∏è. Handle external dependencies:
	
		Externalize configs (env vars, config files, secrets).
		
		Mount volumes if app writes files locally.
	
	4Ô∏è. Testing & debugging:
	
		Build locally ‚Üí run ‚Üí fix issues (file paths, network configs).
		
	5Ô∏è. Create docker-compose for multi-service dependencies (DB, Cache).
	
	
‚úÖ How would you handle logs in production containers?
	üîß Key rule: Don‚Äôt log to files inside container ‚Üí log to stdout/stderr.
	
	‚úÖ Why?
	
		Docker captures stdout/stderr ‚Üí log drivers handle storage.
	
	‚úÖ Logging options:
	
		Use centralized logging tools:
		
		ELK stack (Elasticsearch + Logstash + Kibana)
		
		EFK stack (Fluentd instead of Logstash)
		
		Promtail + Loki + Grafana
		
		Cloud provider solutions: AWS CloudWatch, Azure Monitor, GCP Stackdriver.
		
	docker logs <container-id>

	‚úÖ Production best practice:

		Use log aggregation agent as sidecar or host agent.
		
		Structure logs (JSON logs are easier to parse).
		
		

‚úÖ How do you update running containers in production?
	üßº Containers are immutable ‚Üí you don‚Äôt update containers directly.

	‚úÖ Update flow:
		1Ô∏è. Build new Docker image with updated code/config.
		2Ô∏è. Push updated image to Docker Registry.
		3Ô∏è. Pull new image on production nodes.
		4Ô∏è. Stop existing containers.
		5Ô∏è. Start new containers with updated image.

	‚úÖ In orchestration (K8s, Swarm):

		Update deployment/service ‚Üí orchestrator handles replacement.

	‚úÖ Never patch containers directly.
	
	

‚úÖ What happens if your Docker container crashes?
	üö® Behavior depends on restart policy:

	‚úÖ Without restart policy:

		Container exits ‚Üí remains stopped (Exited status).

	‚úÖ With restart policy:	docker run --restart=always my-app

	Docker automatically restarts the crashed container.
	
	‚úÖ In orchestration (Kubernetes/Swarm):

		Controller automatically restarts failed containers as per pod replica definition.

	‚úÖ Root Cause Debugging:

		Check logs: docker logs <container-id>
		
		Inspect container exit code and resource usage.
		
		Check OOM kills or segfaults.
		
		

‚úÖ How do you handle rolling updates in Docker Swarm/Kubernetes?

	üåÄ In Docker Swarm:
	
	docker service update --image my-app:2.0 my-service
	
	Swarm will perform rolling update automatically.
	
	‚úÖ Control with flags:	docker service update --update-parallelism 2 --update-delay 10s my-service
		
		Updates 2 containers at a time, 10 sec delay.
		
	üåÄ In Kubernetes:
	
	‚úÖ Native rolling updates:

		When you update Deployment object, K8s triggers rolling update:
		
		kubectl set image deployment/my-app my-app=my-app:2.0

	‚úÖ Control rollout behavior:
	
	
		strategy:
			type: RollingUpdate
			rollingUpdate:
					maxUnavailable: 1
					maxSurge: 2
	‚úÖ You can pause, resume, or rollback rollouts.
	
	
	
‚ö†Ô∏è Common Docker Issues in Interviews

| Issue                  | Cause                                 | Resolution                               |
| ---------------------- | ------------------------------------- | ---------------------------------------- |
| High image size        | Unoptimized Dockerfile                | Use multi-stage builds, slim base images |
| Port conflict          | Host port used by another app         | Map to a different host port             |
| File permission issues | UID mismatch between host & container | Use `USER` in Dockerfile                 |
| Network unreachable    | Misconfigured Docker network          | Use correct bridge or overlay network    |



üõ°Ô∏è Docker Best Practices (Interview GOLD)

	Use official base images and keep them updated.
	
	Use multi-stage builds to reduce image size.
	
	Always define HEALTHCHECK in Dockerfile.
	
	Limit container privileges (read-only filesystem, drop capabilities).
	
	Use secrets management (avoid hardcoded credentials).
	
	Clean up unused containers, images, and volumes (docker system prune).
	
	
‚úÖ Namespaces
	üîß What are namespaces?
	
	Linux kernel feature that provides isolation for containers.
	
	Each container gets its own "view" of system resources.
	
	| Namespace | What it isolates           | Example                                    |
	| --------- | -------------------------- | ------------------------------------------ |
	| `pid`     | Process IDs                | Each container sees only its own processes |
	| `mnt`     | Filesystem mounts          | Own filesystem hierarchy                   |
	| `net`     | Network interfaces         | Own network stack (IP, interfaces, routes) |
	| `ipc`     | Interprocess Communication | Own shared memory, semaphores              |
	| `uts`     | Hostname                   | Each container has its own hostname        |
	| `user`    | User IDs                   | Map user IDs inside the container          |
	
	
	‚úÖ Why namespaces?
	
	Containers don‚Äôt interfere with each other or the host.
	
	Gives process-level isolation.
	
‚úÖ cgroups (Control Groups)
	üîß What are cgroups?
	
	Kernel feature that controls resource allocation for processes.
	
	Used by Docker to limit and track resource usage for containers.
	
	Resources managed by cgroups:
	
	| Resource | What it controls                   |
	| -------- | ---------------------------------- |
	| CPU      | Limit number of CPU cores / shares |
	| Memory   | Limit RAM usage                    |
	| Disk I/O | Limit disk read/write              |
	| Network  | Limit network bandwidth            |


	üîß ‚úÖ Why cgroups?
	
	Prevents one container from consuming all resources.
	
	Supports container resource isolation & fair usage.
	
	
	
‚úÖ Image Layers
	üß± What are Docker image layers?
	
		Docker builds images in layers.
		
		Each instruction in your Dockerfile (e.g., FROM, RUN, COPY, ADD) creates a new layer.
		
		
	üß± Why layers?

		Efficient caching.
		
		If a layer hasn‚Äôt changed, Docker reuses it (speeds up rebuilds).
		
		Allows small incremental changes.
		
		
		
‚úÖ Build Context
	üì¶ What is build context?

		The directory you pass to docker build.
		
		Docker sends the entire context (files, folders) to the Docker daemon when building an image.
		
	‚úÖ Why build context matters?

		Larger build context = slower builds.
		
		May accidentally include unnecessary files (bloating the image).

	‚úÖ Solution: Use .dockerignore
	
		Exclude files not needed for build.
		
	‚úÖ This makes builds:

		Faster
		
		Cleaner
		
		Safer (prevents sensitive files being copied into image)
